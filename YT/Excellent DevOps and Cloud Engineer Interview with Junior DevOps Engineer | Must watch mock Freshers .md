## Excellent DevOps and Cloud Engineer Interview with Junior DevOps Engineer | Must watch mock Freshers -- YT -- DevOps and Cloud Labs
---------------------------------------------------------------------------------------------------------------------



today um so this is your interview for the devops and uh Cloud engineer role

um I will just you know share your resume on screen you just helped me go
0:24
through your resume uh yeah how many years of experience you have um specifically in devops and Cloud
0:31
space and we will then start the discussion after that sure
0:36
let me share your resume yeah

About Rakesh
0:43
yes so uh I'm Rakesh working as a senior software engineer but took on two years
0:50
of experience so I started my career in AWS Cloud so my first project was to develop uh sub
0:58
customer support chatbot I developed this chat board entirely using Amazon native services
1:07
so for chatbot I used let's it's a Amazon chatbot service for Lambda I use
1:14
Lambda I used uh code computation basically I used python product python
1:20
as a famous language and SMS to send SMS OTP validation
1:25
height after that API Gateway integration Vegeta so we are automatically creating
1:32
tickets the jira and getting the ticket details from there and keeping it in my
1:38
chatbot to make it more user friendly for the customers and for the database I use the dynamodb
1:46
after completing this project I got some recognition on my teams or after that I
1:53
was asked to move to the devil stream so before that there there were also some
1:59
prerequisites to be completed for joining in the devops team so they asked me to complete uh associate
2:05
certification AWS associate certification so I did developer Association certification
2:11
once after that I went through the basic concepts of divorce like why the watches
2:16
be basically used what what is the reason of using the awards and also some
2:22
networking code search like ipv4 uh subnet mask and some Linux Concepts so
2:29
while while I'm joining I said about engineer right I literally worked as one number of months or two months as a
2:35
junior devops engineer uh but unfortunately at the time the client called off their project due to
2:42
their financial crisis so everyone on my team got another opportunity but I was
2:48
not given that much opportunity to tell us select the next project I chose uh support engineer role uh this
2:56
is uh this is not relevant to the devops but I don't have that much option so uh
3:02
I'm working as a support engineer using servicenow to resolve the tickets Genesis is a technology where I'm
3:09
working as a support engineer but when I'm doing the support engineer job I'm not getting that excitement so
3:16
whenever I complete a task it's a kind of reputative task I'm daily during so I
3:21
thought to switch back to devops so I'm learning on my own I'm using the I'm using the data available in the internet
3:27
and open source to do my structure uh yeah that's all about myself
3:34
all right good yeah even though you don't have much devops experience but your first project you worked on cloud
3:40
and cloud services exposure you have yes and then you have a couple of
3:45
certifications on your name so yes that's a good thing yeah


What is DevOps

well just stop uh presenting this I want to know few more details like
what is your you said you started gathering information what's your understanding of devops uh what it is uh

yeah why why do I was just being used yes devops the watch is not a technology

so the watch is a methodology so it started getting really uh between around

2015 I said so at the time so there is a huge gap between the developers and the option so
whenever the client here the requirements developer to the requirement coding and push it into the
centralized repository this code need to be converted as artifact the artifact need to be deployed by the option but
here we are having so much of difficulties whenever the code is not uh deployed correctly the austrating might
say the there is a problem there is a fault from the development team so there is a huge gap between these two
uh Fields so development team and the operation team so to bridge this Gap devops being introduced so here we are
we are not we are not doing this process manually so we are integrating we are integrating every Service as an
automation process this is eating it's just like a pipeline so it's like water
pipe lens so then the developer click commit button everything everything is
automated until it's deployed so that that's what the user chapter works
and like do you know why they would have started this just to bridge the gap you are saying yes so yes so the client
might give their requirements uh quick so you know the software development life cycle there's a waterfall model and
also we are using agile now so most of the most of the projects is based on agile so we are using that that was is
something I was looking for to support the agile projects yes earlier it used
to be a lot of waterfall kind of projects so you would have lot of time to design and build the solution and the
delivery would be probably six months sometimes one year also now we're working in agile mode we have to deploy
the application every two weeks one week depending upon the maturity of the customer so that's where devops really
comes handy yes devops basically help you implement agile
yeah in the bedroom yeah yes uh I also I wanted to check on your


Shell scripting
6:27
scripting uh you you have mentioned quite a bit of uh shell scripting and uh
6:33
can you give give me like what is the difference between these Scripts
6:38
oh okay so uh I started skull shell scripting after uh completing the
6:45
completing the let's work project so when there is a pre-recordial sites to
6:50
join us at a watch engineer I started scripting I used I I get the knowledge of fundamentals of uh Linux so in the
6:57
scripting I did a small project like I I have uh distribution like Ubuntu and also
7:05
singtos so you know the packages are different so to automate so to automate the
7:11
services to I need to install Services basically on this distributions so I
7:17
created one bash script it will find what packages they are
7:23
using so what packages basically it is and it will install the service as per the distribution
7:30
can you give me one example can you help me with one um you you get some error that there is
7:37
not enough disk space on your uh server how would you troubleshoot that issue
7:42
how would you know how much is the storage on uh that server that you are monitoring
7:49
so oh okay I would give uh so the command we are asking right
7:56
so I would give a yell
8:03
uh okay forget the command what would you check okay uh so so basically we are having a
8:09
command to uh get the CPU details and also memory details but it's not CPU it's a storage
8:15
oh storage basically a disk storage right yes so it is it is full we are
8:21
asking yeah it's fold uh how could I resolve that
8:28
how would you know which which volume or which Drive is full first you
8:35
need to invest start the investigation yeah uh
8:40
and I'm not getting anything on my mind but you will and you will be able to
8:46
Google that give me the command to find the storage and then you can run that command Drive yes yes yes
8:52
that's what that's what I've been doing so probably I need to get good good group of comments
8:59
all right do you know uh from your certifications and your experience what is cider range in Cloud
9:06
yes yeah yes absolutely Shadow range go hand to hand with subnet mask
9:13
ipv4
9:19
so the devices for naming the devices inside the network we are using ipv4
9:25
so when so for debating the network into the stuff that we are using certain masks
9:30
so for the subject mask I need to know the range the first IP is a network IP there is a range between that and also
9:37
the last IP is known as a broadcast IP for this I need to really understand the
9:42
certain password the subnet mask so for example I'm taking uh Class C private IP
9:48
192 168 0.1 okay 0.0.1 something
9:53
the first usable IP would be the network IP the last usable IP would be the
9:59
broadcast apis I mentioned between this I might have 254 usable IP
10:05
right so this can be used as a one subnet so if I'm taking another example like uh
10:12
192 168 0.0 so the first part will be the network part second part will be the
10:19
host part the host part can be converted into the subnets so in this example I might have 256 subnet
10:26
but uh well for one subnet I would have uh 256 usable IP
10:33
so this can be mentioned as a cider uh notation
10:39
for example this 32 bit right ipv4 for the 255 or
10:47
255.255 so when I convert this into the binary I might get CIS 16 24 right so 24
10:55
can be mentioned after the internal IP for in AWS for example or any any other
11:01
Cloud if two such networks have to talk to each other do you know what process
11:06
we follow uh two uh PPC need to communicate with here
11:12
uh so I would I would use VPC peering okay for communicating between the two VPC
11:20
the VPC is basically a virtual private Cloud so I need to decide the English traffic and take this traffic so that's
11:27
all any hearing basic requirement for uh Network pairing to happen or any best
11:34
practice around it um let's practice okay for example I'm I'm
11:42
saying like uh in the VPC uh EA I'm running One Touch of this for example
11:49
I'm taking up Apache right so I'm having my mySQL database on my VPC okay
11:57
so for the request which is coming from the vpca this should be should be related to the
12:04
uh uh this application a question application need to be allowed as an
12:09
inbound traffic for the vpcp so so only allowing the traffic the
12:15
mentioned traffic in the vpcb will be the income in traffic so that would be the best practice
12:21
okay cool that is good so you will have routes from one subnet or one VPC to the
12:27
other one yes yeah yeah anything in context of cider range
12:33
uh cider range so let's see what what if both the uh both the VPC have a cider
12:40
range of 192 168 0.0 uh Slash 24 then how the traffic would
12:47
know which VPC to go to oh okay
12:54
for this uh I would say um
Overlapping IP addresses
13:02
so one so we are having
13:07
so basically the good practice is that you should not have overlapping cider
13:12
ranges so okay you cannot you cannot pair them uh if you have
13:18
uh exactly same or overlapping IP addresses because then your traffic
13:24
would not know which of the VPC it has to Target
13:34
okay can you tell me a bit about uh DNS records you have mentioned uh Route 53
What is DNS
13:39
and other services in your resume yes so what was your role in that
13:46
yeah sure so DNS I have used DNS or one of my projector so DNS is basically
13:52
domain naming system so so it's a like a telephone directory when I give the URL so when uh it basically converts it into
14:01
that IP so corresponding IP the I got DNS from GoDaddy so I used it my it in
14:09
my 453 so whenever uh whenever the user putting the the this domain name so it
14:16
automatically gets the IP from the Route 53 and it will use to forward this
14:22
request to the Tomcat server so it's basically my web application so that's that's a load balancer right
14:29
uh what is load balancer then load balancer I have used again engine is for load balancer
14:35
but what is the difference between load balance and forwarding a request and DNS
14:40
forwarding a request to an IP uh okay load balancer will you usually
14:45
split the traffic with my instances uh uh so in the domain name thing system
14:54
DNS uh 53
15:04
usage of prop 53 okay so so they look very similar right they're both of them
15:09
yes seems like routing the traffic but yes there must be a difference right so no worries
15:15
okay that's fine uh I wanted to know what what sort of experience you have in the devops space like Jenkins or uh
Jenkins
15:23
bamboo bit pocket yeah so if you can explain a little bit in
15:29
that area sure sure so Jenkins I have used Jenkins for the complete CI CD automation so
15:36
this pipeline the I have used uh kit as a git reposit tree and uh from there
15:43
whenever I used booths so whenever the code commits happen it will trigger the
15:49
build so I used I I'm using Java application so I'm using May 1 as my
15:54
build tool so I am creating artifacts from there and the artifacts go into the
15:59
unit testing and uh yeah after the unit testing I will I'm also using the sonar
16:05
Cube for checking the vulnerabilities
16:16
yeah psycho is a kind of graphical interface where I can see my bugs and
16:21
also the vulnerable vulnerabilities the code has and I'm all I can also set the Gateway
16:27
so if the code having this much of bugs it should not uh cross the pipeline so
16:34
it should fail at that place I'm also used to custom Gateway for this
16:40
the if everything is good the code the artifact will be converted I need to
16:45
store the artifact with version so after storing it on my ECR
16:51
the effects will be deployed in the ECS through ECS I I would get the application
16:57
okay so you're using private repository a private ECR to your your own manage yes
17:04
yes my AWS account private is here
17:09
is ACR a regional service or is it a region specific or global
17:16
Service uh it's a it's a regional server the regional service because uh
17:24
I'm a bit confused I'm not sure whether it's a regional or local service no that's fine
17:33
um you have mentioned a bit of ansible and terraform so was it in the same
Ansible and Terraform
17:38
project you were using both these tools no it's it's a different project
17:44
okay yeah so have you written ansible and terraform code yourself
17:49
yes yes is it possible yeah if you can write some ansible
17:55
script and just explain on the notepad now sure it could be hello world that's fine
18:03
okay so um [Music]
18:30
okay I'm chatting the screen it's uh ansible so I'm I'm writing a
18:38
very basic answers uh Playbook so yeah I'm giving them so our name can be
18:46
something like hello world I'm starting my script here so post I
18:57
uh Genie so here I usually mention inventory file so the inventory file basically you have the details of my
19:03
target now I'm starting the tasks
19:09
can there be more than one Targets in the inventory file yes yes absolutely
19:16
so I can have uh the huge range of uh targets that's all basically ansible so
19:25
we can Target uh as many number of servers and we can just with a single
19:31
Playbook we can do the whatever we want on the servers okay
19:37
that's why I think this is good this is good okay the Way You Are
19:42
RX you have very good understanding of yeah specifically you didn't start writing
Beanstalk
19:49
just by yourself like you are explaining as well in parallel which is yes nice
19:56
um you also worked on Beanstalk yes yes I did can you explain what was
20:03
the use case sure yeah so in my AWS cacd project
20:09
I used Beanstalk so before that I was using my background as a background to
20:16
host uh any reason why you selected Beanstalk or is was it your decision or your company some architect finalized it
20:23
for you no so it's it's the so I explode in the internet so this is basically uh
20:29
so for the website web application so we are using pin stack so it's a it's
20:34
very easy so yeah it's completely automated ec2 servers sorry or the load
20:40
balancer or the AST group everything is created for you okay you just need to allow the security groups with your
20:45
other services then it will start working that's the reason so okay
20:51
that was if you wanted to it to be very simplified for uh Developers for understanding work on the source code
20:56
and load balancer server creation Auto scaling is automatically managed yes yes
21:02
awesome Yep what are roles in AWS
21:10
okay so basically IM roles can be used to for the user and for the groups and
21:18
also for the services so if for example if my Lambda need to speak with uh PS3 I
21:24
need to give the yes three rule for the Lambda servers it goes with groups as well as users so
21:32
whoever have the roles they will be able to access the services
21:38
okay so it's basically allowing AWS Services access to other services yes
21:49
how long was this chatbot this Lex board project that you were working on
21:56
uh I was working about four to five months on that project so I was the only person working on that so I usually I
22:03
used to connect with my managers uh on Peak basis so they will give the next task to be
22:10
completed so that's how the LED support okay which other areas you connected this
Database
22:17
chatbot to like there is a huh Lambda function in this yeah using
22:24
python but what other systems was it talking to to some database as well
22:30
yes uh so uh it it the flow starts with the so it's it's a I basically mentioned
22:37
like uh customer support chatbot so usually the customer will raise ticket
22:42
on their website the client client's website so they want a separate chatbot
22:48
to make this process more simplified so they want us to make a chatbot where
22:53
they will just give the uh their problem it need to be created as a ticket and
22:59
the ticket number need to be displayed for the user the user is a can use a
23:05
ticket number and query it so this function gets simplified so for that uh the first of all user need to have the
23:13
so the user need to have the account yeah over here so I need to validate
23:19
them for that I given those details in my database then would be so whenever
23:24
the user enters their phone number it checks that dynamodb if that is the number it will send the OTP to them and
23:31
it will validate their connection why why dynamodb is it is it useful because you were working on it right so only you
23:37
selected it or some yeah I selected it uh any reason why you
23:43
selected dynamodb for this and not RDS or some other cluster or yes okay I feel like dynamodb is uh way
23:51
more powerful so it's it's serverless and they are having the huge set of data uh so for that Dynam will be using key
24:00
value class it's having low latency so probably I thought this would be the good thing to choose so they just want
24:06
they just don't want your data to dynamodb like say how do you
24:12
how are you populating the dynamodb uh so I was not given that huge data so
24:19
I'm I have given my own data for the testing so they just want to have the
24:24
Prototype after that they said they will give the main process so I was basically
24:29
building my prototype okay so it wasn't a real project then uh yes so usually we have a discussion
24:37
with clients so so they they will say their development so then its thing need to be developed so once after the
24:43
completion of the Prototype so they said uh they will give the project and the allocation of the project details but in
24:50
in you know right in SQL Server or in any um RDS I can write some insert
24:57
queries I don't know how to how to do that in dynamodb
25:02
oh how do you push data to dynamodb
25:08
okay I didn't use uh this you know this kind of not face
25:15
any issue pushing that data because if you have hundreds and hundreds of Records yeah
25:21
how would you push that data to dynamodb you would have probably used the console and what happened
25:37
how you can push data to dynamodb sure yeah
25:42
let's talk about a bit of kubernetes now you have quite a bit of experience with
Kubernetes
25:49
kubernetes as well so what was the use case because it's not fitting into this project yeah I yeah so I just want to explore
25:57
kubernetes on my own so basically I learned Docker so what is what is the usage of token so for uh so to maintain
26:05
the Dockers for example if one Docker goes down so there is need to be high
26:10
availability in Docker as well so that's what we are using Management Service like orchestration service like
26:15
kubernetes and also there is other services like eks and other services but kubernetes is being famous so I learned
26:23
some of the basic concepts of kubernetes I understood the architecture and how it
26:28
is being used and also I used uh some some basic things on kubernetes
26:35
like mini Cube I installed mini Cube so it's just one note
26:40
so I did that it's not used for in any project as such
26:46
it's more for self-learning yes okay not not implemented in the project
26:53
but you still talk a lot of architectural terms uh there so it's
26:58
good you have learned quite a bit of it it seems uh have you
27:04
have you used how do you deploy to a cluster
27:09
uh uh okay deploy so I need to deploy
27:16
so you have built your container images now how in they are in ECR how do you push them to Cluster and have you used
Deploying Kubernetes
27:24
any automation there or cube CTL or how do you push that
27:29
yes so so I didn't remember so I basically follow the instruction from
27:35
the open sources from the website so but I do remember a command line so I
27:40
created I created once one command on S3 so whenever I
27:45
whenever I think that command it automatically automatically clear creates the
27:51
uh the kubernetes so from there I think I have done I have
27:58
done the container running over there so in the end of the course
28:03
okay it's a kind of fake so it is here
28:09
so you didn't do any CI CD on kubernetes it's through some commands you you
28:15
believe it was deployed yeah yeah not not in that uh
28:22
what what is your understanding of microservices framework why do we use kubernetes elastic
Why Kubernetes
28:29
bean stock that was doing the job right yeah yeah so why do we need to
28:34
complicate life and use this yeah so uh we are using container
28:40
service so uh basically the containers are being used because uh
28:45
so to to isolate and also give the high availability with a low cost cost
28:51
capital expenditure operational expenditure we are using containers for the containers uh to maintain the
28:58
containers so we we absolutely need kubernetes the kubernetes can handle not only the docker containers for every
29:04
container so that's what we are having pots under the pods uh we can use the
29:10
containers so that's that's a real usage of
29:15
kubernetes but what problem does they solve so it's just
What problem does Kubernetes solve
29:21
just the management of containers yes uh so it manages containers and also
29:29
it provides High availability and uh it is higher availability how does it provide h a
29:35
yeah okay so uh whenever for example I'm running one service on only one server
29:42
okay so if the server went down the service will not be working so in that
29:48
case I need to be having two or more services to server to host the services
29:53
so that's that's called high availability so if even if one server went down I
29:58
will be having two other servers again that that can be solved by elastic bean
30:04
stock using Auto scaling group into different regions or two different phases then that can be solved right
30:12
yeah but the elastic bean stack will not be able to handle the containers okay that's what that's what makes it
30:19
more of a container management that's why it's yeah but what what other benefits does
30:24
microservices offer uh micro Services my uh it gives a
30:33
so as I mentioned the capital expenditure operational expenditure is comparatively low
30:38
why it is to manage the environment then
30:45
maybe to monitor the equivalent is you would need additional monitoring tools so you are adding operational cost and
What other benefits does microservices offer
30:52
operational effort to do it yeah isn't it yeah so I'm just comparing the VMS with
30:59
the kubernetes so that's what I'm going out on this point uh so you're asking about uh
31:07
what are the two benefits of microservices oh okay
31:13
so I would say the services are uh in the very small it's very small Services
31:19
okay so after combining the one process every process combined we get the last
31:25
result or last uh service so that's a major benefit so even if one service one
31:32
microservice get affected we can use other services to get the application
31:38
that would be there so if so basically two benefits would be probably which I
31:43
would articulate would be that you can scale these Services individually if you
31:48
believe that uh one of your dashboard is going to be viewed more than any other
31:53
service and dashboard takes a lot of resources and you want to scale
31:58
specifically a service which presents the dashboards then you can scale that
32:04
automatically second benefit would be that if you just have to change the dashboard screen and nothing else has to
32:10
be changed you can deploy just the dashboard related microservice
32:17
sort of isolation and then the scalability that's required for service
32:23
okay cool I think that's pretty much Rakesh I
32:29
wanted to check um you did a very good job actually uh
32:34
yeah I I could say that in some of the questions uh some of some of the time you go beyond uh one or two year devops
32:43
engineer you use your language comes out uh yeah that of a senior and although
32:48
the project uh chatbot kind of project are very small in nature yes yeah I
32:54
think I have myself built or I have seen people building chatbot in the hackathon which is a weekend activity
33:01
yeah and they will they will integrate with say WhatsApp or Twitter and all
33:06
that will send notification to external system so it can be very basic structure
33:12
can be done in in a very short amount of time but obviously if customers have to use it then you would have a bit of
33:18
testing make it robust so it integrates with their system so I I could say that
33:24
you have good experience on a lot of cloud services and devops yeah yeah
33:30
any question that you have noticed before we close uh so I would ask so I'm
33:36
just started exploring the works so what what can be the areas I need to concentrate okay we'll discuss it uh
33:43
offline we'll close the introduction and then we'll discuss it definitely
33:49
thank you so much thank you
