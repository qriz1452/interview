## Cloud Engineer and DevOps Engineer Live Interview -- Youtube -- DevOps and Cloud Labs 

=====================================================================================

Q1 . I think uh if you can help me explain a little bit about your profile uh what sort of skill set you have uh what sort of experience you bring some of the responsibilities that you have been handling in your last role and from there we can start.

Ans : oh sure definitely yes I do have four years of experience my current company is Golden City digital Technologies where I'm working as a cloud engineer so here I got an opportunity to explore three different clouds that's AWS Azure and gcp uh where the major Focus was on finops cost optimization methodologies uh like we worked on different services in AWS like including eks redshift EMR ECR cloud cloud watch cloud trail so what we usually do is we analyze the service we test the service using apis and clis we also use Postman and we are also using mongodb and SQL DB we use Robo 3T for that time does for SQL we do use SQL studio so we analyze the service test the service and then Define the policy so we do have subcategory in finops like idle service being idle it is being orphaned and I am majorly focused on cloud Technologies

Q2 . uh what do you offer through that do you train people build some products ?

uh yes we are also focusing on building uh a product as well but not yet doubly fledged um like we are integrating different Technologies uh like we do have devops tools so we are trying out new methods but as of now we provide services to clients um that's still a major Focus as of now

so it's a service provider like every analysis okay got it

so which is for criteria networks for now currently working for code stack and I'm also planning to work for a terraform as well that's with sindria a U.S client um yeah that's the new project we are getting 

okay so you work with different uh these customers and then you implement based on their skills their requirements what what what they require

yes we provide the service and we are also exploring uh new products as well to build as our company owned product 

cool and so it's a multi-cloud uh experience you said right all the cloud providers and okay all three clouds okay 

so which is your strong uh area then uh which is your strong Cloud platform that you work on

uh AWS okay and but as of now um I'm also comfortable with I sure because um I worked for almost one and a half year and as well as the gcp but most of the services are from AWS and azure gcp a few of them all together around 40 plus Services we have worked on and we do provide the entire logic like using we provide.

it's you have those that experience right not your company 

uh yes not my company it's uh you are working on that right okay so uh I mean I was just telling the team uh I worked on like 20 plus services so we do have a team where we uh coordinate with each other we review whatever the policies they have defined or I have defined so that way we have exposure to many services okay I see you you are searching it's like 50 plus so much yes 

AWS associate and these are valid certifications right now yes yes that's right 

all right um okay I I got a good idea uh on the profile so I I wanted to understand you mentioned a bit about cost optimization uh so what sort of is it a customer requirement to work on cost optimization ?

uh yeah so uh post stack mainly focus on phenops so they want to reduce the cost in the client accounts so what we do is first we test in the dev environment how our logic works so for example if I have to give a simple say ec2 instance uh now we go with uh say idle policy so what do we do is we check with the metrics for example CPU and memory utilization we have a threshold say five percent if it is less than that then the customer is not using and it is a waste of time having that in their environment so we tell that customers that uh this is of no use since you're not using it for a certain period period um and there'll be also provide them how the cost works as well whether it is billing role logic or unit rate logic we have complex policies as well so which uh have really helped the customers in cutting down the cost 

okay but then this there are a lot of tools right they provide these kind of reports there's is there anything beyond that uh do you like identifying idle resources one case for uh optimization anything else uh do you understand reserved instance

s yes yes spot institutions Reserve dedicated host is we not only worked on the simple terms a complex conflict policies as well for example a service might have different compute tires and for example if I talk about file store in gcp it has Enterprise basic standard so we analyze uh what Enterprise features are what standard features are and what basic features are whether customer is using all those features to its Optimum level if it's not being used to how to detect that and how cost reducing happens if we ask them to switch over that and we also recommend them as well so based on the we just provide what all the alternative recommendations they can use but it's completely based on client whichever the recommendations suitable for them they're gonna use that 

okay for example if some customer is running their workloads in eks maybe what all areas you will analyze for cost optimization 

so for example uh AWS e case first we'll check whether we have a master uh node and worker nodes so we'll check whether the essence masternode is a password we will not be doing anything there worker note will analyze what type of instance they are using it whether they they are using it to its Optimum level if that particular instances instance type is not being used to its optimal levels for a gcp whatever I mean memory and CPU whatever the instance type provide if they are not using will ask them to shift to a distance a different instant type and also we do have pods as well so we do recommend the horizontal scaling vertical or Auto scaling if the pods are not being used we do have metrics for pod using Cube CTL we analyze those metrics whether the pods are being used completely or not on board level or instance level on container level also weighted but uh not to um okay so and

if you have to optimize the container images that also is a big space type like big challenge

yes yes it's a complex method okay all right okay uh what about your devops uh area um are you comfortable uh

yes from past five months uh I've been trained on that uh basically all kubernetes so all the basic concepts like what is devops uh what are the tools used in devops how it works so basically I understand sort of uh you would use oh sure so in devops we first go with the planning and then the source code and then build testing and then we have after testing we do release and then operate and monitor continuous integration continuous deployment and then continuous um continuous development continuous uh first is continuous development continuous integration continuous deployment and then the configuration management and then we have a continuous monitoring so first if we I'm using uh devops planning Tool uh that's nothing but assured boats we are using from past two years where we plan uh what is the project about and uh what comes under the projects like epic under that we do have subcategories as features and then we have user story and then tasks so that's the planning tool which I'm using uh that's actually reports and next comes the source code source code a bitbucket uh SVN and GitHub mainly I've worked on now or GitHub only so um uh GitHub I have experience on git stash uh stash conflict how to solve that and master Branch how to create a user branch and merge it to the a remote repo from local to uh remote and then pull requests so that's I've worked on I've not worked on SVN and big bucket so only GitHub and then so next comes to containerization Tool integration tool containerization tools Docker compose Docker file and then we have integration tool Jenkins the bamboo I worked on Jenkins so where I'll create a build pipeline um I worked on amazing 

how will Jenkins talk to Azure or Azure devops you you mentioned started with uh

yes I have implemented using a Helm chart so during uh so we create what I have done is I have created a Usher eks uh in Azure portal and then um I have um then implemented Jenkins on it using the helm chart and then I have manually as well as scripted not much but manually I've done a lot of things like building the pipeline uh terraform yes time I'm learning a little bit of this one a terraform is infrastructure code just to automate the infrastructure project where you have a case yeah I have not worked on uh AWS uh eks but Azure a case I have tried with the telephone code um still I am learning so we do have a new project coming up uh where we have to give a test and then enter into the project so for that we are still working on it yes we have used the telephone code so using telephone you have created the the atas in Azure portal you yes you are giving conflicting me messages you have created in Azure portal or you have created the cluster using terraform or both I have tried out first I have need to know how it works in the portal so after which I have shifted to a code because that's the automation because because I usually what I do is I go with the portal experience like how exactly it works and then with the code so that's easy to see how it works and we also provided cost optimization on that uh and then um telephone code that we have used okay any any experience with ansible no much experience configuration management tool for upgrades uh we're gonna use a Playbook Center yes I don't have much experience but I love to work on those tools as well because at other companies as well like how how many weeks have you started trying for new position and oh it just started from last week okay how is the market are you getting a lot of calls how is the scenario from past one week I just got through two three calls one is for uh cognizant the other is for reminding okay cool the market is good you're getting costs yes and Cloud right yes based on your mainly you have Cloud experience I believe right how is your Linux skill set yeah initially I worked on Linux itself so I do have good experience on that uh where I used to manage is manage uh user accounts creating the users and then providing permissions ACL Access Control list and then you have to look at some log file which is being populated in parallel How would you repeat that file uh Slash word slash locks where you will get the information about whatever the user have created or done and their file is being populated right now you want to monitor that log file in real time so you can't you can't look at the last hundred lines because the last hundred lines will be overwritten very shortly and then there will be fresh lines added to it oh oh you want me to monitor a log file file you want to monitor log file to give get some errors or something like that okay get some errors but the data is usually in the late last written blogs right last written 10 or 15 or 100 lines but the log file is getting populated like it's being overwritten every or not overwritten but frequently updated oh we can use Greg command in the log file whichever we want to look into it so your voice is breaking yeah is it better not yes okay uh on the uh uh AWS or Azure what is this public subnet and private subnets do you understand what is the main difference between all these these differences yes yes so public sermons subnets where uh user is giving we give all the traffic to that public subnet where user can access but private subnets only the private IPS are allowed not the public IPS by other internet so for public subnet we basically don't use net Gateway for private subnet we do use lab Gateway or some other like connecting with other VPC but not with the public directly on contact okay I'm just trying to see based on your resume and where you would fit into is is there a any sort of scripting experience you have can you write some code as well I've written for uh that like terraform like I told I have done it for Azure case and still learning that and probably two weeks or three weeks I'll catch it with telephone so no problem can you uh give me or I will just maybe I will find some some policy and uh maybe you can help me explain that bucket policy okay so let me send something in the chat box and see if you can explain this policy okay so we are allowing public access to the yeah it's on the screen yes so we are allowing public access to the resource in order to get objects from that specific year in that specific bucket what does the star means um okay example bucket slash star uh I think any object from that bucket okay if the then object is resource is this one right yes so inside that bucket we do have objects what is this the one on screen uh principle star um sorry I'm not getting kit um yeah I think any object can be picked from the bucket yeah correct that is correct I just wanted to understand what does this star means you got it right I think maybe you are getting some idea from this line or but I wanted to understand on what is this principle star means okay principal star and what does this action means oh action is where you perform any tasks so your uh your action is to get the object from Mystery bucket so this is the resource where which bucket we have this is the action then what what would this be this possibly is the user right where who okay right who is trying to access star star means uh public uh you can say it's not specified any uh user or role there okay okay can you write a bit of terraform code or something you can explain as well uh or or if any any of the language where you are comfortable with you can write a some simple use case maybe a hello world in that project okay maybe a Docker file and just just keep explaining like uh what what you are writing and while you are writing oh okay so well I just uh know how it works when I see the code but right now I'm not able to remember it just just a simple even if it is not correct like syntax wise or something I want to understand whether you know conceptually and I believe you are certified so you would know um those sort of things that that's the level I I need to understand or if you want I can I can pull a Docker file and you can explain yes Michael please take me some time okay let I have a file let me uh share it and yep oops is that oh okay so first we're gonna pull the base image that is the container base image that will be a node and the latest version as for clean and then directory inside the container what does this specify um the version and next we are creating a contained a working directory in a container because uh Docker file will be of same name but uh folder should be different so we're gonna create a folder slash uh ABP and then copy the package Json and package log Json file to the working directory okay so we are copying this package.json to this uh working directory that's uh app and then you're gonna install all the dependencies using current command so we're always used um uh basically when you want to install ink packages from VM repo EBT so that will install the packages so while uh building the image and next copy the rest of the application code to the working directory uh yes dot uh the application code with extension if it is a Linux or a Windows dot exe or if it's a Linux we have dot word or jar so whatever the extension file we're gonna copy it and then we're going to export the expose the port number so here the port number is three thousand so we're gonna export uh expose that port number what does this mean uh to expose uh the port number uh in the sense we're gonna expose that application on the specific port number that's uh 3000 and then yes CMD is used to uh oh actually um to open not a paint to replace the packages or why local dinner is running okay packages or any statements to the Target location if you want to replace while container is running we'll use that command form to start the application yes okay all right some of the comments would have helped sorry some of the comments in the code would have helped you a little bit or you oh no I know the structure of the docker file so it was simple good good all right um so what area other than that we can I wanted to understand a bit of Jenkin file do you understand what the Jenkins file is uh yes so Jenkins files were um uh I don't have much experience on that um Jenkins have done all the manual activities so for Jenkins we do have a declarative and descriptive um where we gonna specify the um build a pipeline task like if I take me when we do have six tasks so the task it can be a scripted in Jenkins file and then the jobs will be sorry I'm not able to see your video yep I'm there yes uh yeah so automatically all the tasks which has been uh which has been specified by the ability tool it will be done like for me when we have some six tasks code review compile unit test uh metric check package deploy so all that can be uh just uh dumped into into a code and that will perform the job okay um can you tell some experience you earlier mentioned about uh cloudwatch agent or Cloud watch monitoring what sort of experience you have a cloud watch basically we monitor the Matrix of various resources we have also set up the alarm like whenever the threshold increases the alarm has to populate and a user has to get the notification notification I worked on SNS monitoring in Cloud watch and there is also a cloud watch agent when do we need agent a cloud watch agent I've used for uh so AWS or eks so we do require cloudwatch agent okay why do we need agent what's the advantage disadvantage of an agent disadvantage advantage and disadvantage like because when I create an ec2 instance I do get some some metrics out of the box I don't need an agent for that you're right what specific use cases do we need agent for the cloud watch agent specific use cases um I do remember that it is for a few services we do require your Cloud watch agent but um not able to remove this remember the specific use case any use case because I don't need agent for CPU and uh basic stuff like just to get the CPU and RAM kind of thing right uh why do I need agent at all then oh right um for specific metrics which will not be available in Cloud watch that we can populate in Cloud watch agent for example like any any example of that sort of metrics uh pod metrics like we do have um uh or the number of pods you know have you configured any any logs to be sent over cloudwatch assuming the log stream yeah uh yes I had configured lock screen so you you would need an agent configured for that right so you mean foreign for that okay no logs as in PPC flow logs bpc flow logs what are VPC flow logs uh where we get information about the network like the IPS which have pink that vc2 instance you I think you are mixing up to Concepts right like or is it me not asking I want some logs from the C2 instance not not the VPC flow data blocks from easy to install something some some you you earlier mentioned like I have a slash War slash log has some some data I want that in Cloud watch logs group so anyway okay so you need agent for such cases you need agent installed on that ec2 instance and then that can stream the logs to logs group you bring and uh where you can add a lot of value anything you you want to ask before we close the discussion as of no yeah I'm good with it any any last comment you want to make before we close uh yes I am too interested in devops technology and that's the reason I'm opting for uh different options so here I've got a recent I've got a telephone project where I'll be working on it but I still want to work on devops tools so I'm very much interested in that so yes I'll be happy to drop them lots of such projects and opportunities so yeah thank you all right then have then we'll close the discussion and while share the feedback sure thank you thank you thanks take care bye thank you bye
